------Training ApprxReinforcementAgent------
Training on 100001 epochs.
Averages were 7.138248617513825 epochs and -1.145448545514545 rewards....
Finished training.

------Testing ApprxReinforcementAgent------


Test 1 with starting state 79000000000001110100001000100011160110001010100001121100000000000:
000000000
00   0 00
00 000 00
0   h0  0
00 0 0 00
00  r  00
000000000

--starting state--
000000000
00   0 00
00 000 00
0    0  0
00 0h0 00
00  r  00
000000000

step  : 1
reward: -1

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 2
reward: 4

Testing Summary:
  Agent took 2 steps and earned a reward of 4.


Test 2 with starting state 79000000000001110100001000100062110110001010100001111100000000000:
000000000
00   0 00
00 000 00
0hr  0  0
00 0 0 00
00     00
000000000

--starting state--
000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 1
reward: 5

Testing Summary:
  Agent took 1 steps and earned a reward of 5.


Test 3 with starting state 79000000000001110100006000100011120110001010100001111100000000000:
000000000
00   0 00
00h000 00
0   r0  0
00 0 0 00
00     00
000000000

--starting state--
000000000
00   0 00
00 000 00
0 h r0  0
00 0 0 00
00     00
000000000

step  : 1
reward: -1

000000000
00   0 00
00 000 00
0  hr0  0
00 0 0 00
00     00
000000000

step  : 2
reward: -2

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 3
reward: 3

Testing Summary:
  Agent took 3 steps and earned a reward of 3.


Test 4 with starting state 790000000000011101000026000100011110110001010100001111100000000000:
000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

--starting state--
000000000
00h  0 00
00r000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 1
reward: -1

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 2
reward: 4

Testing Summary:
  Agent took 2 steps and earned a reward of 4.


Test 5 with starting state 79000000000001110100001000100011110110001010600001111200000000000:
000000000
00   0 00
00 000 00
0    0  0
00 0 0h00
00    r00
000000000

--starting state--
000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 1
reward: 5

Testing Summary:
  Agent took 1 steps and earned a reward of 5.


Test 6 with starting state 79000000000001110100002000100011110110001060100001111100000000000:
000000000
00   0 00
00r000 00
0    0  0
00 0h0 00
00     00
000000000

--starting state--
000000000
00   0 00
00r000 00
0   h0  0
00 0 0 00
00     00
000000000

step  : 1
reward: -1

000000000
00   0 00
00r000 00
0  h 0  0
00 0 0 00
00     00
000000000

step  : 2
reward: -2

000000000
00   0 00
00r000 00
0 h  0  0
00 0 0 00
00     00
000000000

step  : 3
reward: -3

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 4
reward: 2

Testing Summary:
  Agent took 4 steps and earned a reward of 2.


Test 7 with starting state 79000000000001110100001000100011110110001060100001111200000000000:
000000000
00   0 00
00 000 00
0    0  0
00 0h0 00
00    r00
000000000

--starting state--
000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00  h r00
000000000

step  : 1
reward: -1

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00   hr00
000000000

step  : 2
reward: -2

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 3
reward: 3

Testing Summary:
  Agent took 3 steps and earned a reward of 3.


Test 8 with starting state 79000000000001110100001000100011210110001010100001611100000000000:
000000000
00   0 00
00 000 00
0  r 0  0
00 0 0 00
00 h   00
000000000

--starting state--
000000000
00   0 00
00 000 00
0  r 0  0
00 0 0 00
00h    00
000000000

step  : 1
reward: -1

000000000
00   0 00
00 000 00
0  r 0  0
00h0 0 00
00     00
000000000

step  : 2
reward: -2

000000000
00   0 00
00 000 00
0 hr 0  0
00 0 0 00
00     00
000000000

step  : 3
reward: -3

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 4
reward: 2

Testing Summary:
  Agent took 4 steps and earned a reward of 2.


Test 9 with starting state 79000000000001110100001000100011110110001010600002111100000000000:
000000000
00   0 00
00 000 00
0    0  0
00 0 0h00
00r    00
000000000

--starting state--
000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00r   h00
000000000

step  : 1
reward: -1

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00r  h 00
000000000

step  : 2
reward: -2

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00r h  00
000000000

step  : 3
reward: -3

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00rh   00
000000000

step  : 4
reward: -4

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 5
reward: 1

Testing Summary:
  Agent took 5 steps and earned a reward of 1.


Test 10 with starting state 79000000000001110100002000100011110110001010100001116100000000000:
000000000
00   0 00
00r000 00
0    0  0
00 0 0 00
00   h 00
000000000

--starting state--
000000000
00   0 00
00r000 00
0    0  0
00 0 0 00
00  h  00
000000000

step  : 1
reward: -1

000000000
00   0 00
00r000 00
0    0  0
00 0 0 00
00 h   00
000000000

step  : 2
reward: -2

000000000
00   0 00
00r000 00
0    0  0
00 0 0 00
00h    00
000000000

step  : 3
reward: -3

000000000
00   0 00
00r000 00
0    0  0
00h0 0 00
00     00
000000000

step  : 4
reward: -4

000000000
00   0 00
00r000 00
0 h  0  0
00 0 0 00
00     00
000000000

step  : 5
reward: -5

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 6
reward: 0

Testing Summary:
  Agent took 6 steps and earned a reward of 0.
Training Metrics:
+---------+--------+---------+
| episode | epochs | rewards |
+---------+--------+---------+
|    1    |   31   |   -31   |
|  10001  |   7    |    -1   |
|  20001  |   5    |    1    |
|  30001  |   15   |    -9   |
|  40001  |   7    |    -1   |
|  50001  |   2    |    4    |
|  60001  |   1    |    5    |
|  70001  |   2    |    4    |
|  80001  |   4    |    2    |
|  90001  |   2    |    4    |
|  100001 |   2    |    4    |
+---------+--------+---------+
Testing Metrics:
+------+--------+---------+
| test | epochs | rewards |
+------+--------+---------+
|  1   |   2    |    4    |
|  2   |   1    |    5    |
|  3   |   3    |    3    |
|  4   |   2    |    4    |
|  5   |   1    |    5    |
|  6   |   4    |    2    |
|  7   |   3    |    3    |
|  8   |   4    |    2    |
|  9   |   5    |    1    |
|  10  |   6    |    0    |
+------+--------+---------+
Metric Averages:
+---------+---------+
|  Metric | Average |
+---------+---------+
|  epochs |   3.1   |
| rewards |   2.9   |
+---------+---------+
Weights Table
+------------+---------------------+
|  Feature   |        Weight       |
+------------+---------------------+
|    bias    | -17.885349629037442 |
| dist-to-r1 |  24.701515037585516 |
+------------+---------------------+
------Cache for SimpleExtractor------
Cache has 1003310 accesses and 3217204 additions.
 79000000000001610100001000100021110110001010100001111100000000000 had 3483 references.
 79000000000001110100006000100021110110001010100001111100000000000 had 15602 references.
 79000000000006110100001000100021110110001010100001111100000000000 had 5975 references.
 79000000000001160100001000100021110110001010100001111100000000000 had 1460 references.
 79000000000001110100001000100026110110001010100001111100000000000 had 28797 references.
 79000000000001110100006000100011110110001010100001211100000000000 had 8190 references.
 79000000000001110100001000100011610110001010100001211100000000000 had 5661 references.
 79000000000001110100001000100011110110006010100001211100000000000 had 12977 references.
 79000000000001110100001000100061110110001010100001211100000000000 had 4563 references.
 79000000000006110100001000100011110110001010100001211100000000000 had 5158 references.
 79000000000001110100001000100016110110001010100001211100000000000 had 12226 references.
 79000000000001610100001000100011110110001010100001211100000000000 had 3380 references.
 79000000000001160100001000100011110110001010100001211100000000000 had 1498 references.
 79000000000001120100001000100016110110001010100001111100000000000 had 31270 references.
 79000000000001120100006000100011110110001010100001111100000000000 had 32179 references.
 79000000000001120100001000100011610110001010100001111100000000000 had 18370 references.
 79000000000001120100001000100011110110006010100001111100000000000 had 18380 references.
 79000000000001120100001000100061110110001010100001111100000000000 had 11365 references.
 79000000000001120100001000100011160110001010100001111100000000000 had 10752 references.
 79000000000001110100002000100016110110001010100001111100000000000 had 1 references.
(base) macintosh@BlckMagikMan StaghuntAgent % 
