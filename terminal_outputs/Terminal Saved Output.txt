------Training Q-Learning Agent------
Saving table as 'tables/q-table-2'===========----------------] 72.6% ...
Stopped at 7266 epochs.
Trained over 10001 epochs.
Results for 3 epochs:
+---------+---------------------+--------+---------+-----------------------+
| episode |      % < delta      | epochs | rewards |         delta         |
+---------+---------------------+--------+---------+-----------------------+
|    1    |         0.0         |   29   |   -23   |   0.9480943738656987  |
|   4496  | 0.10008896797153025 |   14   |    -8   | 0.0033652251456103223 |
|   6085  |         0.2         |   16   |   -10   |  0.000354331463140197 |
+---------+---------------------+--------+---------+-----------------------+

------Testing Q-Learning Agent------
Agent Table Size: 400
Testing..


test 1 with starting state 79000000000001110100006000100021110110001010100001111100000000000:
Agent's Q-Values for state 79000000000001110100006000100021110110001010100001111100000000000:
{(2, 1): 0.09295032052260009, (2, 3): 2.9999982502707723}
000000000
00   0 00
00h000 00
0r   0  0
00 0 0 00
00     00
000000000

--starting state--
000000000
00   0 00
00 000 00
0rh  0  0
00 0 0 00
00     00
000000000

step  : 1
reward: -1

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 2
reward: 4

Testing Summary:
  Agent took 15 steps and earned a reward of 4.


test 2 with starting state 79000000000001110100001000100011110110001010100002111600000000000:
Agent's Q-Values for state 79000000000001110100001000100011110110001010100002111600000000000:
{(6, 4): -1.7292731320352894, (5, 5): 0.11999984227971881}
000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00r   h00
000000000

--starting state--
000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00r  h 00
000000000

step  : 1
reward: 3

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00r h  00
000000000

step  : 2
reward: 2

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00rh   00
000000000

step  : 3
reward: 1

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 4
reward: 6

Testing Summary:
  Agent took 15 steps and earned a reward of 6.


test 3 with starting state 79000000000001160100001000100012110110001010100001111100000000000:
Agent's Q-Values for state 79000000000001160100001000100012110110001010100001111100000000000:
{(3, 1): -0.5032803147188627}
000000000
00  h0 00
00 000 00
0 r  0  0
00 0 0 00
00     00
000000000

--starting state--
000000000
00 h 0 00
00 000 00
0 r  0  0
00 0 0 00
00     00
000000000

step  : 1
reward: 5

000000000
00h  0 00
00 000 00
0 r  0  0
00 0 0 00
00     00
000000000

step  : 2
reward: 4

000000000
00   0 00
00h000 00
0 r  0  0
00 0 0 00
00     00
000000000

step  : 3
reward: 3

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 4
reward: 8

Testing Summary:
  Agent took 15 steps and earned a reward of 8.


test 4 with starting state 79000000000001110100001000100011110160001010100001211100000000000:
Agent's Q-Values for state 79000000000001110100001000100011110160001010100001211100000000000:
{(6, 3): -1.754677724168056}
000000000
00   0 00
00 000 00
0    0 h0
00 0 0 00
00 r   00
000000000

--starting state--
000000000
00   0 00
00 000 00
0    0h 0
00 0 0 00
00 r   00
000000000

step  : 1
reward: 7

000000000
00   0 00
00 000 00
0    0  0
00 0 0h00
00 r   00
000000000

step  : 2
reward: 6

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00 r  h00
000000000

step  : 3
reward: 5

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00 r h 00
000000000

step  : 4
reward: 4

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00 rh  00
000000000

step  : 5
reward: 3

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 6
reward: 8

Testing Summary:
  Agent took 15 steps and earned a reward of 8.


test 5 with starting state 79000000000001110100001000100012110610001010100001111100000000000:
Agent's Q-Values for state 79000000000001110100001000100012110610001010100001111100000000000:
{(6, 2): -3.6780288475614156, (7, 3): -3.6710531475707655, (6, 4): -2.9061376969027246}
000000000
00   0 00
00 000 00
0 r  0h 0
00 0 0 00
00     00
000000000

--starting state--
000000000
00   0 00
00 000 00
0 r  0  0
00 0 0h00
00     00
000000000

step  : 1
reward: 7

000000000
00   0 00
00 000 00
0 r  0  0
00 0 0 00
00    h00
000000000

step  : 2
reward: 6

000000000
00   0 00
00 000 00
0 r  0  0
00 0 0 00
00   h 00
000000000

step  : 3
reward: 5

000000000
00   0 00
00 000 00
0 r  0  0
00 0 0 00
00  h  00
000000000

step  : 4
reward: 4

000000000
00   0 00
00 000 00
0 r  0  0
00 0h0 00
00     00
000000000

step  : 5
reward: 3

000000000
00   0 00
00 000 00
0 r h0  0
00 0 0 00
00     00
000000000

step  : 6
reward: 2

000000000
00   0 00
00 000 00
0 rh 0  0
00 0 0 00
00     00
000000000

step  : 7
reward: 1

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 8
reward: 6

Testing Summary:
  Agent took 15 steps and earned a reward of 6.
(base) macintosh@BlckMagikMan StaghuntAgent %
