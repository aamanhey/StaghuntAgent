Approximate Agent
------Training ApprxReinforcementAgent------
Training on 100000 epochs.
Averages were 8.16083 epochs and 2.25383 rewards.============] 100.0% ... Time Elapsed: 2324 seconds, Episode: 99999
Finished training.

------Testing ApprxReinforcementAgent------


Test 1 with starting state 790000000000011101000010001000111101100070260100001111400000000000:
000000000
00   0 00
00 000 00
0    0  0
00h0 0 00
00    s00
000000000

--starting state--
000000000
00   0 00
00 000 00
0 h  0  0
00 0r0s00
00  Ĥ  00
000000000

step  : 1
reward: -1

000000000
00   0 00
00 000 00
0  h 0  0
00 0r0 00
00 Ĥ  s00
000000000

step  : 2
reward: -2

000000000
00   0 00
00 000 00
0   h0  0
00 0r0 00
00Ĥ  s 00
000000000

step  : 3
reward: -3

000000000
00   0 00
00 000 00
0    0  0
00Ĥ0 0 00
00   s 00
000000000

step  : 4
reward: -4

Testing Summary:
  Agent took 4 steps and earned a reward of -4.


Test 2 with starting state 79000000000001110100006000100011110140001010100001711200000000000:
000000000
00   0 00
00Ĥ000 00
0    0 s0
00 0 0 00
00 h  r00
000000000

--starting state--
000000000
00   0 00
00 000 00
0 Ĥ  0s 0
00 0 0 00
00  h r00
000000000

step  : 1
reward: -1

000000000
00   0 00
00 000 00
0  Ĥ 0s 0
00 0 0 00
00   hr00
000000000

step  : 2
reward: -2

000000000
00   0 00
00 000 00
0   Ĥ0s 0
00 0 0 00
00     00
000000000

step  : 3
reward: -3

Testing Summary:
  Agent took 3 steps and earned a reward of -3.


Test 3 with starting state 79000000000001110100001000100014110170001060100001112100000000000:
000000000
00   0 00
00 000 00
0 s  0 h0
00 0Ĥ0 00
00   r 00
000000000

--starting state--
000000000
00   0 00
00 000 00
0   Ĥ0h 0
00s0 0 00
00   r 00
000000000

step  : 1
reward: -1

000000000
00   0 00
00 000 00
0  Ĥ 0  0
00s0 0h00
00   r 00
000000000

step  : 2
reward: -2

000000000
00   0 00
00 000 00
0 Ĥ  0  0
00 0 0 00
00s  rh00
000000000

step  : 3
reward: -3

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 4
reward: -4

Testing Summary:
  Agent took 4 steps and earned a reward of -4.


Test 4 with starting state 79000000000007110100001000100012110410001010100001161100000000000:
000000000
00h  0 00
00 000 00
0 r  0s 0
00 0 0 00
00  Ĥ  00
000000000

--starting state--
000000000
00   0 00
00h000 00
0 r  0  0
00 0 0s00
00   Ĥ 00
000000000

step  : 1
reward: -1

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 2
reward: -2

Testing Summary:
  Agent took 2 steps and earned a reward of -2.


Test 5 with starting state 790000000000011101000010001000141101100010102700001161100000000000:
000000000
00   0 00
00 000 00
0 s  0  0
00 0 0 00
00  Ĥ  00
000000000

--starting state--
000000000
00   0 00
00s000 00
0    0  0
00 0Ĥ0r00
00    h00
000000000

step  : 1
reward: -1

000000000
00s  0 00
00 000 00
0   Ĥ0  0
00 0 0r00
00   h 00
000000000

step  : 2
reward: -2

000000000
00   0 00
00s000 00
0  Ĥ 0  0
00 0 0r00
00  h  00
000000000

step  : 3
reward: -3

000000000
00   0 00
00s000 00
0 Ĥ  0  0
00 0h0r00
00     00
000000000

step  : 4
reward: -4

000000000
00s  0 00
00Ĥ000 00
0   h0  0
00 0 0r00
00     00
000000000

step  : 5
reward: -5

000000000
00Ĥs 0 00
00 000 00
0  h 0  0
00 0 0r00
00     00
000000000

step  : 6
reward: -6

000000000
00 Ĥs0 00
00 000 00
0 h  0  0
00 0 0r00
00     00
000000000

step  : 7
reward: -7

000000000
00   0 00
00h000 00
0    0  0
00 0 0r00
00     00
000000000

step  : 8
reward: -8

000000000
00hĤs0 00
00 000 00
0    0  0
00 0 0r00
00     00
000000000

step  : 9
reward: -9

000000000
00 h 0 00
00 000 00
0    0  0
00 0 0r00
00     00
000000000

step  : 10
reward: -10

000000000
00 Ĥ 0 00
00 000 00
0    0  0
00 0 0r00
00     00
000000000

step  : 11
reward: -11

000000000
00   0 00
00 000 00
0    0  0
00 0 0r00
00     00
000000000

step  : 12
reward: 14.0

Testing Summary:
  Agent took 12 steps and earned a reward of 14.0.


Test 6 with starting state 79000000000001110600001000100011410110001010100002171100000000000:
000000000
00   0Ĥ00
00 000 00
0  s 0  0
00 0 0 00
00r h  00
000000000

--starting state--
000000000
00   0 00
00 000Ĥ00
0 s  0  0
00 0h0 00
00r    00
000000000

step  : 1
reward: -1

000000000
00   0 00
00 000 00
0 s h0Ĥ 0
00 0 0 00
00r    00
000000000

step  : 2
reward: -2

000000000
00   0 00
00 000 00
0  h 0  0
00s0 0Ĥ00
00r    00
000000000

step  : 3
reward: -3

000000000
00   0 00
00 000 00
0 h  0  0
00 0 0 00
00    Ĥ00
000000000

step  : 4
reward: -4

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00r  Ĥ 00
000000000

step  : 5
reward: -5

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00r Ĥ  00
000000000

step  : 6
reward: -6

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00rĤ   00
000000000

step  : 7
reward: -7

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 8
reward: -2

Testing Summary:
  Agent took 8 steps and earned a reward of -2.


Test 7 with starting state 790000000000067110100001000400011110120001010100001111100000000000:
000000000
00   0 00
00 000s00
0    0 r0
00 0 0 00
00     00
000000000

--starting state--
000000000
00 Ĥ 0 00
00h000s00
0    0 r0
00 0 0 00
00     00
000000000

step  : 1
reward: -1

000000000
00Ĥ  0s00
00 000 00
0 h  0 r0
00 0 0 00
00     00
000000000

step  : 2
reward: -2

000000000
00   0 00
00Ĥ000s00
0  h 0 r0
00 0 0 00
00     00
000000000

step  : 3
reward: -3

000000000
00   0 00
00 000s00
0 Ĥ h0 r0
00 0 0 00
00     00
000000000

step  : 4
reward: -4

000000000
00   0 00
00 000s00
0  Ĥ 0 r0
00 0h0 00
00     00
000000000

step  : 5
reward: -5

000000000
00   0 00
00 000s00
0   Ĥ0 r0
00 0 0 00
00  h  00
000000000

step  : 6
reward: -6

000000000
00   0 00
00 000s00
0    0 r0
00 0Ĥ0 00
00   h 00
000000000

step  : 7
reward: -7

000000000
00   0 00
00 000s00
0    0 r0
00 0 0 00
00  Ĥ h00
000000000

step  : 8
reward: -8

000000000
00   0 00
00 000s00
0    0 r0
00 0 0h00
00   Ĥ 00
000000000

step  : 9
reward: -9

000000000
00   0 00
00 000 00
0    0 r0
00 0 0 00
00    Ĥ00
000000000

step  : 10
reward: -10

000000000
00   0 00
00 000 00
0    0 r0
00 0 0Ĥ00
00     00
000000000

step  : 11
reward: -11

000000000
00   0 00
00 000 00
0    0 r0
00 0 0 00
00     00
000000000

step  : 12
reward: 14.0

Testing Summary:
  Agent took 12 steps and earned a reward of 14.0.


Test 8 with starting state 79000000000001120600001000700011110140001010100001111100000000000:
000000000
00  r0Ĥ00
00 000h00
0    0 s0
00 0 0 00
00     00
000000000

--starting state--
000000000
00  r0 00
00 000Ĥ00
0    0hs0
00 0 0 00
00     00
000000000

step  : 1
reward: -1

000000000
00  r0 00
00 000 00
0    0Ĥs0
00 0 0h00
00     00
000000000

step  : 2
reward: -2

000000000
00  r0 00
00 000 00
0    0  0
00 0 0 00
00    h00
000000000

step  : 3
reward: -3

000000000
00  r0 00
00 000 00
0    0Ĥs0
00 0 0 00
00   h 00
000000000

step  : 4
reward: -4

000000000
00  r0 00
00 000 00
0    0  0
00 0 0 00
00  h  00
000000000

step  : 5
reward: -5

000000000
00  r0 00
00 000 00
0    0Ĥs0
00 0h0 00
00     00
000000000

step  : 6
reward: -6

000000000
00  r0 00
00 000 00
0   h0  0
00 0 0 00
00     00
000000000

step  : 7
reward: -7

000000000
00  r0 00
00 000 00
0  h 0Ĥs0
00 0 0 00
00     00
000000000

step  : 8
reward: -8

000000000
00  r0 00
00 000 00
0 h  0  0
00 0 0 00
00     00
000000000

step  : 9
reward: -9

000000000
00  r0 00
00h000 00
0    0Ĥs0
00 0 0 00
00     00
000000000

step  : 10
reward: -10

000000000
00h r0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 11
reward: -11

000000000
00 hr0 00
00 000 00
0    0Ĥs0
00 0 0 00
00     00
000000000

step  : 12
reward: -12

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 13
reward: -13

Testing Summary:
  Agent took 13 steps and earned a reward of -13.


Test 9 with starting state 790000000000061201000010001000111101100047010100001111100000000000:
000000000
00Ĥ r0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

--starting state--
000000000
00  r0 00
00Ĥ000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 1
reward: -1

000000000
00  r0 00
00 000 00
0 Ĥ  0  0
00 0 0 00
00     00
000000000

step  : 2
reward: -2

000000000
00  r0 00
00 000 00
0    0  0
00 0 0 00
00     00
000000000

step  : 3
reward: 23.0

Testing Summary:
  Agent took 3 steps and earned a reward of 23.0.


Test 10 with starting state 79000000000001110100001000100076110110001010200001411100000000000:
000000000
00   0 00
00 000 00
0hĤ  0  0
00 0 0r00
00 s   00
000000000

--starting state--
000000000
00   0 00
00 000 00
0Ĥh  0  0
00 0 0r00
00s    00
000000000

step  : 1
reward: -1

000000000
00   0 00
00 000 00
0 Ĥh 0  0
00 0 0r00
00 s   00
000000000

step  : 2
reward: -2

000000000
00   0 00
00 000 00
0  Ĥh0  0
00 0 0r00
00 s   00
000000000

step  : 3
reward: -3

000000000
00   0 00
00 000 00
0   Ĥ0  0
00 0h0r00
00 s   00
000000000

step  : 4
reward: -4

000000000
00   0 00
00 000 00
0    0  0
00 0Ĥ0r00
00     00
000000000

step  : 5
reward: -5

000000000
00   0 00
00 000 00
0    0  0
00 0 0r00
00   h 00
000000000

step  : 6
reward: -6

000000000
00   0 00
00 000 00
0    0  0
00 0 0r00
00  sĤh00
000000000

step  : 7
reward: -7

000000000
00   0 00
00 000 00
0    0  0
00 0 0 00
00 sĤ  00
000000000

step  : 8
reward: -8

Testing Summary:
  Agent took 8 steps and earned a reward of -8.
Training Metrics:
+---------+--------+---------+
| episode | epochs | rewards |
+---------+--------+---------+
|    1    |   11   |    -5   |
|  10001  |   1    |    -1   |
|  20001  |   1    |    -1   |
|  30001  |   13   |   13.0  |
|  40001  |   6    |   20.0  |
|  50001  |   2    |   24.0  |
|  60001  |   2    |   24.0  |
|  70001  |   13   |   13.0  |
|  80001  |   7    |    -7   |
|  90001  |   11   |   15.0  |
+---------+--------+---------+
Testing Metrics:
+------+--------+---------+
| test | epochs | rewards |
+------+--------+---------+
|  1   |   4    |    -4   |
|  2   |   3    |    -3   |
|  3   |   4    |    -4   |
|  4   |   2    |    -2   |
|  5   |   12   |   14.0  |
|  6   |   8    |    -2   |
|  7   |   12   |   14.0  |
|  8   |   13   |   -13   |
|  9   |   3    |   23.0  |
|  10  |   8    |    -8   |
+------+--------+---------+
Metric Averages:
+---------+---------+
|  Metric | Average |
+---------+---------+
|  epochs |   6.9   |
| rewards |   1.5   |
+---------+---------+
Weights Table
+------------------+---------------------+
|     Feature      |        Weight       |
+------------------+---------------------+
|       bias       |  -4.260272327251896 |
| h1-payoff-for-r1 |  15.847548669576101 |
|  h1-dist-to-r1   | -14.314182825664808 |
| h1-payoff-for-s1 | -19.663389417313596 |
|  h1-dist-to-s1   |  3.4412862177808488 |
| h1-payoff-for-h2 |         0.0         |
|  h1-dist-to-h2   |  35.322268058866406 |
| h2-payoff-for-s1 |  -16.84788928130505 |
|  h2-dist-to-s1   |  2.0335361497779294 |
| h2-payoff-for-r1 |  12.378554565271775 |
|  h2-dist-to-r1   | -12.579685773514262 |
| h2-payoff-for-h1 |         0.0         |
|  h2-dist-to-h1   |  35.322268058866406 |
+------------------+---------------------+
------Cache for StaghuntExtractor------
Cache has 899874 accesses and 3343230 additions.
 790000000000014710100002000100011110110001010100001161100000000000 had 98 references.
 79000000000004170100002000100011110110001010100001116100000000000 had 2 references.
 790000000000014710100002000100011110110001060100001111100000000000 had 73 references.
 790000000000014710100002000100011110110001010100001116100000000000 had 54 references.
 790000000000014710100002000100011110110001010100001611100000000000 had 91 references.
 790000000000014710100002000100011160110001010100001111100000000000 had 87 references.
 790000000000014710100002000100011610110001010100001111100000000000 had 138 references.
 790000000000014710100002000100016110110001010100001111100000000000 had 220 references.
 7900000000000147101000026000100011110110001010100001111100000000000 had 129 references.
 790000000000014710100002000100011110110006010100001111100000000000 had 158 references.
 790000000000014710100002000100061110110001010100001111100000000000 had 93 references.
 790000000000014710100002000100011110110001010100006111100000000000 had 118 references.
 790000000000064710100002000100011110110001010100001111100000000000 had 32 references.
 790000000000011201000010006000111101470001010100001111100000000000 had 856 references.
 79000000000001120600001000100011110740001010100001111100000000000 had 16 references.
 790000000000011201000010001000111107640001010100001111100000000000 had 122 references.
 79000000000001120100001000600011110140001010700001111100000000000 had 50 references.
 790000000000011201000010001000111101460001010700001111100000000000 had 62 references.
 790000000000011201000010001000111101400010107600001111100000000000 had 66 references.
 7900000000000111010000100010001111011000101027000014611100000000000 had 1 references.
(base) macintosh@BlckMagikMan StaghuntAgent % 
